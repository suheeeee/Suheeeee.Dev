---
title: "CS231N Lec.02 Image Classification"
date: "2021-07-11T15:47:32.169Z"
template: "post"
draft: false
slug: "cs231n-lec-2"
category: "CS231N"
tags:
  - "cs231n"
  - "deep learning"
description: "Lec.02 Image Classification 강의 정리본. The data-driven approach, K-nearest neighbor, Hyperparameters, Linear classification I"
# socialImage: "./banner.png"
---

본 게시물은 [CS231n: Convolutional Neural Networks for Visual Recognition (2017)](http://cs231n.stanford.edu/2017/syllabus.html) 강의의 영상과 슬라이드를 기반을 작성 되었습니다.

---

## Image Classification
- 컴퓨터 비전 분야에서의 core task이자 CS342n에서 주로 다루기도하는 문제

### Image Classification은 어떻게 이루어 지는가?
1. 이미지를 입력받는다.
2. 정해진 카테고리 집합에서 컴퓨터가 이미지를 보고 어디에 속할지를 고른다.

👉 인간에게는 쉽지만 컴퓨터에게는 매우 어렵다.<br>
👉 컴퓨터에게 이미지 == 거대한 숫자판<br>
![01_semantic_gap.png](./01_semantic_gap.png)
👉 `Semantic Gap` : 컴퓨터가 실제로 보고 있는 <u>숫자판</u>과, <u>고양이</u>라고 하는 의미 사이에 존재하는 간극

### Image Classification은 컴퓨터에게 어렵다!
![02_difficault.png](./02_difficault.png)
1. viewpoint variation
  - 이미지에 미묘한 변화만 주더라고 픽셀 값이 광범위하게 변화한다.
  - 예를들어 고양이가 가만히 있더라도 카메라의 이동에 따라 픽셀값이 달라진다.
2. 조명 illumination
3. 변형 deformation
4. 가려짐 occlusion
5. 배경과의 유사함 Background Clutter
6. 클래스내의 다양성 Intraclass Variation

이런 것들을 모두 고려하였을 때, 컴퓨터가 이미지의 의미를 알아챈다는 것은 매우 어려워 보인다.<br>
👉 일부 제한된 상황이라면 잘 동작하는 기술이 존재한다!<br>
👉 앞으로의 강의에서는 이것이 어떻게 가능해졌는지 볼 것이다.

### 이전까지 이미지를 인식하기 위해 해왔던 시도
😺 **고양이 인식하기**
![03_image_classifier.PNG](./03_image_classifier.PNG)
1. 이미지에서 edgds를 계산, 다양한 corners와 edges를 각 카테고리(귀, 코, ...)로 분류
2. 이들로부터 고양이라는 특징(귀가 두 개 코가 하나 등 고양이를 인식하기 위한 규칙)을 찾아낸다.

이러한 방식은 잘 동작하지 않는다.<br>
- 위에서 언급했던 문제들에 대해 강건하지 못하고
- 인식하고자 하는 새로운 객체가 등장하면 처음부터 모든 동작을 반복해 한다.

👉 다양한 객체들에 유연하게 적용가능한 알고리즘 필요<br>
👉 ML key insight : **`Data-Driven Approach`**가 등장하게 됨

### Data-Driven Approach
카테고리에 대한 규칙을 정하는 것이 아니라..!

1. 카테고리에 해당하는 엄청 많이 데이터를 수집하고
2. 데이터들을 이용하여 ML classifier(=model) 학습
3. 학습된 classifier를 새로운 이미지로 테스트한다.

```python
def train(images, labels):
  # Maching learning !
  return model

def predict(model, test_images):
  # Use model to predict labels
  return test_labels
```

🌟 지금부터 할 것 : 간단한 ML classifier부터 살펴보기

## Nearest Neighbor
```python
def train(images, labels):
  # Memorize all data and labels
  return model

def predict(model, test_images):
  # Predict the label of the most similar training image
  return test_labels
```
- Train 단계 : 모든 데이터와 라벨을 기억
- Predict 단계 : 새로운 이미지와 기존 이미지(학습에 사용된 이미지)를 비교하여 가장 유사한 학습 이미지의 라벨을 반환

### 예시로 보는 Nearest Neighbor의 동작(feat. CIFAR-10)
![04_cifar_10_nn.PNG](./04_cifar_10_nn.PNG)

CIFAR-10은 10개의 클래스(비행기, 자동차, 새, ...)로 분류되는 50000장의 학습용 이미지와 10000장의 테스트 이미지로 구성되어 있다.

오른편의 그림은 Nearest Neighbor를 이용하여 예측을 진행한 결과이다. 그림의 왼쪽열이 테스트 이미지이고 오른쪽 방향으로 학습 이미지를 테스트 이미지와 유사한 순으로 정렬한 것이다. 2번째 줄의 2번째까지는 테스트 이미지의 카테고리과 같은 개를 유사한 이미지로 출력하지만 그 이후로는 사슴 혹은 말과 같은 다른 카테고리의 요소들을 출력하고 있다.<br>
👉 Nearest Neighbor 알고리즘 적용시 학습 데이터셋에서 가장 가까운 샘플을 찾아냄<br>
👉 이게 성능면에서는 좋지 않지만, 지금 단계에서 예시로 보기에는 가치가 있다.

### Nearest Neighbor 주요 안점
`두 이미지 쌍을 어떻게 비교할 것인가?`<br>
`비교를 위하여 어떤 비교함수를 사용할 것인가?`

앞의 예제 L1 Distrance(Manhattan distance, 이하 L1 Dist)를 사용하였다.

![05_NN_L1_dist.PNG](./05_NN_L1_dist.PNG)


이는 두 이미지에서 같은 픽셀 위치에 있는 값끼리 뺀 후 절대값을 취하고 이후 모든 픽셀에 대한 수행결과를 더하는 것으로 계산된다. 단순한 동작이지만 <u>두 이미지간의 차이를 어떻게 측정할 것인가?</u>에 대한 구체적 답변이 된다.

### Nearest Neighbord의 한계점
#### 예측 시간
N개의 training set이 존재할 때, Nearest Neighbor의 `Train/Predict 함수의 속도`는 어떻게 될까?
- Train O(1) : 단순 저장
- Predict O(N) : N개의 학습 이미지와 입력 이미지를 모두 비교해야하기 때문, 느림

모바일 혹은 브라우저 또는 다른 저전력 장치에서 실행되는 실제 서비스에서는 학습시간은 상대적으로 오래 걸려도 괜찮으나 예측 시간(test/prediction time)이 빠르기를 원한다. 하지만, Nearest Neighbor는 그 수요와 정반대로 동작한다.

#### 분류 성능의 한계
Nearest Neighbor이 실제로 동작한 결과는 아래와 같은 결정 영역(decision regions)으로 그려낼 수 있다.

![06_decision_regions.png](./06_decision_regions.png)

결정 영역에서 각 점은 학습 데이터이고 점의 색은 클래스(label)이 된다. 이 결정 영역의 색은 평면의 각 픽셀에 대해 훈련 데이터에서 가장 가까운 점을 찾아 해당 점의 클래스 레이블로 칠한 것이다. 이 경우 두가지 문제를 존재한다.

1. 초록색 영역 한 가운데에 노란색 섬이 존재.
2. 초록색 영역이 파란색 영역을 침범

이는 특정한 노란색 점 혹은 초록색 점이 잡음(noise)이거나 잘못된 정보(spurioius)인 경우 발생할 수 있다. 이를 통하여 Nearest Neighbor는 여러 상황에 대하여 충분히 강건하지 못하다 말할 수 있다.

## K-Nearest Neighbors(KNN)
위에서 언급된 Nearest Neighbor의 문제점을 해결하고자 KNN이 등장하게 된다. 이는 Distance metric를 이용하여 가까운 이웃을 `K`개만큼 찾고 이웃끼리 **투표(voting)**를 하여 가장 많은 득표수를 올린 레이블로 예측하는 방식이다.

+) 추가 : 투표 결과의 결정방식에도 다양한 방법이 존재하고 위에 언급된 가장 많은 득표수를 올린 레디블을 선택하는 방식을 Majority voting이라 한다.

### K
![07_knn_decision_regions.png](./07_knn_decision_regions.png)

KNN에서 사용자가 선택하게 되는 값으로 투표에 참여할 이웃의 수를 의미한다.

대체로 K가 1보다 클때 결정경계가 부드러워지고 좋은 결과를 보이고 있다.

K가 1보다 클 때, 라벨이 결정되지 못한 흰색영역이 등장하는데 이는 투표 결과에서 승자를 확정할 수 없는 지역을 의미한다. 이 부분을 추론 혹은 랜덤으로 값을 채울 수도 있지만, 현재는 간단한 예제를 보는 것이 목적이기 때문에 흰색으로 칠해 두었다.

### Distance Metric
KNN에서 사용자가 선택하게 되는 또 다른 값으로 <u>서로 다른 점들을 어떻게 비교할 것인가</u>에 대한 방법이다.

![08_distance_metric.png](./08_distance_metric.png)

이전까지의 예제에서는 L1 Dist로 픽셀간 차이의 절대값의 합을 구하였다. 이번에 추가로 소개할 방법은 L2 Distance(Euclidean Distance, 이하 L2 Dist)로 두 거리의 차의 제곱합의 제곱근을 계산하는 것으로 구할 수 있다.

위의 그림은 그래프는 원점에서 떨어져 있는 거리가 같은 점들을 모아 놓은 것이다. 강의에서는 거리 척도(L1, L2)에 따라 공간의 근본적인 기하하적 구조 자체가 서로 다르게 된다고 표현하고 있다.

- L1 Dist은 좌표계에 영향을 받는다.
  - 특정 벡터의 각각 요소들이 개별적인 의미를 가진다면(키/몸무게) L1 Dist가 더 유용할 수도 있다.
  - 다른 말로하면, 어떤 벡터가 있고 각 요소가 어떤 특별한 의미를 가질 때 더 유용할 수도 있다.
- 그렇지 않고 각 요소간의 실직적인 의미를 잘 모르는 경우에는 L2가 더 유용할 수도 있다.
- Problem-dependent 문제 의존적

![09_L1_L2.png](./09_L1_L2.png)

위 그림에서는 거리 척도에 따라 발생하는 기하하적 변화를 확인 가능하다. 경계의 모양이 L1 Dist일 때, L2 Dist일 때가 서로 다른 것을 볼 수 있다. L1은 좌표축의 영향을 받기 때문에 경계가 수직 혹은 수평에 가깝다. L2는 축의 영향을 받지 않기 때문에 더 자연스럽게 결정경계가 만들어진다.

다양한 거리척도를 이용하면 KNN으로 다양한 데이터를 다룰 수 있다. 벡터/이미지/문장 등 데이터 사이에 거리를 구할 수 있는 척도가 존재한다면 KNN 적용이 모두 가능하다. 추가로 KNN은 아주 단순한 알고리즘이어서 새로운 문제를 접햇을 때 가장 먼저 간단히 시도해볼만하다.

